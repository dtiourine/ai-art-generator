{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T01:00:05.325468Z",
     "start_time": "2024-08-29T01:00:03.111233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from art_generator.config import PROCESSED_DATA_DIR"
   ],
   "id": "3db249befb7ab0e8",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T01:00:05.330367Z",
     "start_time": "2024-08-29T01:00:05.326473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_random_image(dataset):\n",
    "    random_index = np.random.randint(len(dataset))\n",
    "    image, label = dataset[random_index]\n",
    "    return image, label"
   ],
   "id": "96b5d06cb09772ec",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T01:00:05.336780Z",
     "start_time": "2024-08-29T01:00:05.331373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_random_image_sizes(directory, num_images=2):\n",
    "    # Get all image files in the directory\n",
    "    image_files = [f for f in os.listdir(directory) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
    "    \n",
    "    # Randomly select images\n",
    "    selected_images = random.sample(image_files, min(num_images, len(image_files)))\n",
    "    \n",
    "    # Get and print sizes\n",
    "    for image_file in selected_images:\n",
    "        image_path = os.path.join(directory, image_file)\n",
    "        with Image.open(image_path) as img:\n",
    "            print(f\"{image_file}: {img.size}\")"
   ],
   "id": "a65c146ce85382d5",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T01:00:05.356276Z",
     "start_time": "2024-08-29T01:00:05.337785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "directory_path = PROCESSED_DATA_DIR / 'monet_jpg'\n",
    "get_random_image_sizes(directory_path)"
   ],
   "id": "2d8f114699e35ff5",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T01:00:05.361358Z",
     "start_time": "2024-08-29T01:00:05.358283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_size = 256\n",
    "\n",
    "dataset = ImageFolder(root=PROCESSED_DATA_DIR, \n",
    "                      transform=transforms.Compose([transforms.Resize(image_size),\n",
    "                                                    transforms.CenterCrop(image_size),\n",
    "                                                    transforms.ToTensor(),\n",
    "                                                    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "                                                    ]))"
   ],
   "id": "8bbaf6cb02cf5e89",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T01:00:05.521978Z",
     "start_time": "2024-08-29T01:00:05.361358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image, label = get_random_image(dataset)\n",
    "plt.imshow(image.permute(1,2,0))"
   ],
   "id": "62cc68b0a24e15e",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T01:00:05.525015Z",
     "start_time": "2024-08-29T01:00:05.521978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 128\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "id": "47b09d48fd9553f7",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T01:00:06.257099Z",
     "start_time": "2024-08-29T01:00:05.525015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Plot some training images\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "plt.show()"
   ],
   "id": "958a8eaa420be162",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T01:00:06.260522Z",
     "start_time": "2024-08-29T01:00:06.258104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# custom weights initialization called on ``netG`` and ``netD``\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ],
   "id": "8725e251de93a6a4",
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-29T01:00:06.266063Z",
     "start_time": "2024-08-29T01:00:06.260522Z"
    }
   },
   "source": [
    "# Generator Code\n",
    "nz = 100\n",
    "ngf = 64\n",
    "nc = 3\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 32, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 32),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*32) x 4 x 4``\n",
    "            nn.ConvTranspose2d(ngf * 32, ngf * 16, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 16),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*16) x 8 x 8``\n",
    "            nn.ConvTranspose2d( ngf * 16, ngf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*8) x 16 x 16``\n",
    "            nn.ConvTranspose2d( ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*4) x 32 x 32``\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*2) x 64 x 64``\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 128 x 128\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 256 x 256\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T01:00:06.425890Z",
     "start_time": "2024-08-29T01:00:06.266063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create the generator\n",
    "ngpu = 1\n",
    "netG = Generator(ngpu).to(device)\n",
    "netG.apply(weights_init)\n",
    "print(netG)"
   ],
   "id": "c20b0df741289860",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T01:00:06.430271Z",
     "start_time": "2024-08-29T01:00:06.425890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ndf = 64\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Critic, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 256 x 256\n",
    "            nn.Conv2d(nc, ndf, 4, stride=2, padding=1, bias=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 128 x 128\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, stride=2, padding=1, bias=True),\n",
    "            nn.InstanceNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 64 x 64\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, stride=2, padding=1, bias=True),\n",
    "            nn.InstanceNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 32 x 32\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, stride=2, padding=1, bias=True),\n",
    "            nn.InstanceNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 16 x 16\n",
    "            nn.Conv2d(ndf * 8, ndf * 16, 4, stride=2, padding=1, bias=True),\n",
    "            nn.InstanceNorm2d(ndf * 16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*16) x 8 x 8\n",
    "            nn.Conv2d(ndf * 16, ndf * 32, 4, stride=2, padding=1, bias=True),\n",
    "            nn.InstanceNorm2d(ndf * 32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*32) x 4 x 4\n",
    "            nn.Conv2d(ndf * 32, 1, 4, stride=1, padding=0, bias=True),\n",
    "            # output size. 1 x 1 x 1\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1)"
   ],
   "id": "afa6e1d2761de79",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T01:00:06.435422Z",
     "start_time": "2024-08-29T01:00:06.431273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# \n",
    "# class Discriminator(nn.Module):\n",
    "#     def __init__(self, ngpu):\n",
    "#         super(Discriminator, self).__init__()\n",
    "#         self.ngpu = ngpu\n",
    "#         self.layers = nn.ModuleList([\n",
    "#             # input is (nc) x 256 x 256\n",
    "#             nn.Conv2d(nc, ndf, 4, stride=2, padding=1, bias=False),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             # state size. (ndf) x 128 x 128\n",
    "#             nn.Conv2d(ndf, ndf * 2, 4, stride=2, padding=1, bias=False),\n",
    "#             nn.BatchNorm2d(ndf * 2),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             # state size. (ndf*2) x 64 x 64\n",
    "#             nn.Conv2d(ndf * 2, ndf * 4, 4, stride=2, padding=1, bias=False),\n",
    "#             nn.BatchNorm2d(ndf * 4),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             # state size. (ndf*4) x 32 x 32\n",
    "#             nn.Conv2d(ndf * 4, ndf * 8, 4, stride=2, padding=1, bias=False),\n",
    "#             nn.BatchNorm2d(ndf * 8),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             # state size. (ndf*8) x 16 x 16\n",
    "#             nn.Conv2d(ndf * 8, ndf * 16, 4, stride=2, padding=1, bias=False),\n",
    "#             nn.BatchNorm2d(ndf * 16),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             # state size. (ndf*16) x 8 x 8\n",
    "#             nn.Conv2d(ndf * 16, ndf * 32, 4, stride=2, padding=1, bias=False),\n",
    "#             nn.BatchNorm2d(ndf * 32),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             # state size. (ndf*32) x 4 x 4\n",
    "#             nn.Conv2d(ndf * 32, 1, 4, stride=1, padding=0, bias=False),\n",
    "#             nn.Sigmoid()\n",
    "#             # output size. 1 x 1 x 1\n",
    "#         ])\n",
    "# \n",
    "#     def forward(self, input):\n",
    "#         x = input\n",
    "#         print(f\"Input shape: {x.shape}\")\n",
    "#         for i, layer in enumerate(self.layers):\n",
    "#             x = layer(x)\n",
    "#             print(f\"After layer {i} ({layer.__class__.__name__}): {x.shape}\")\n",
    "#         return x.view(-1, 1).squeeze(1)\n",
    "# \n",
    "# # Test the Discriminator\n",
    "# def test_discriminator():\n",
    "#     # Set random seed for reproducibility\n",
    "#     torch.manual_seed(999)\n",
    "# \n",
    "#     # Hyperparameters\n",
    "#     ngpu = 1\n",
    "#     nc = 3  # Number of channels in the training images. For color images this is 3\n",
    "#     ndf = 64  # Size of feature maps in discriminator\n",
    "# \n",
    "#     # Create the Discriminator\n",
    "#     netD = Discriminator(ngpu)\n",
    "# \n",
    "#     # Create a sample input\n",
    "#     batch_size = 128\n",
    "#     sample_input = data[0]\n",
    "#     # sample_input = torch.randn(batch_size, nc, 64, 64)\n",
    "# \n",
    "#     # Run the sample input through the discriminator\n",
    "#     print(\"Running sample input through the discriminator:\")\n",
    "#     output = netD(sample_input)\n",
    "# \n",
    "#     print(f\"\\nFinal output shape: {output.shape}\")\n",
    "# \n",
    "# # Run the test\n",
    "# test_discriminator()"
   ],
   "id": "e70c98bc105acfc3",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T01:00:06.471738Z",
     "start_time": "2024-08-29T01:00:06.468931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Test the Discriminator\n",
    "# def test_discriminator():\n",
    "#     # Set random seed for reproducibility\n",
    "#     torch.manual_seed(999)\n",
    "# \n",
    "#     # Hyperparameters\n",
    "#     ngpu = 1\n",
    "#     nc = 3  # Number of channels in the training images. For color images this is 3\n",
    "#     ndf = 64  # Size of feature maps in discriminator\n",
    "# \n",
    "#     # Create the Discriminator\n",
    "#     netD = Discriminator(ngpu, nc, ndf)\n",
    "# \n",
    "#     # Create a sample input\n",
    "#     batch_size = 128\n",
    "#     # sample_input = data[0]\n",
    "#     sample_input = torch.randn(batch_size, nc, 64, 64)\n",
    "# \n",
    "#     # Run the sample input through the discriminator\n",
    "#     print(\"Running sample input through the discriminator:\")\n",
    "#     output = netD(sample_input)\n",
    "# \n",
    "#     print(f\"\\nFinal output shape: {output.shape}\")\n",
    "# \n",
    "# # Run the test\n",
    "# test_discriminator()"
   ],
   "id": "bd8e11bf072d71b1",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T01:00:07.112317Z",
     "start_time": "2024-08-29T01:00:06.968089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "netC = Critic(ngpu).to(device)\n",
    "netC.apply(weights_init)\n",
    "print(netC)"
   ],
   "id": "3b0631238095ccb6",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T01:00:08.019127Z",
     "start_time": "2024-08-29T01:00:08.014126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Gradient penalty function\n",
    "def compute_gradient_penalty(critic, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN-GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    alpha = torch.rand(real_samples.size(0), 1, 1, 1, device=device)\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    critic_interpolates = critic(interpolates)\n",
    "    fake = torch.ones(real_samples.size(0), 1, device=device, requires_grad=False)\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=critic_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "# Wasserstein loss\n",
    "def wasserstein_loss(y_pred, y_true):\n",
    "    return torch.mean(y_true * y_pred)\n",
    "\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 5e-5\n",
    "beta1 = 0.5\n",
    "n_critic = 5  # Number of critic iterations per generator iteration\n",
    "lambda_gp = 10  # Gradient penalty lambda hyperparameter\n",
    "\n",
    "# Setup RMSProp optimizers for both G and C\n",
    "optimizerD = optim.RMSprop(netC.parameters(), lr=lr)\n",
    "optimizerG = optim.RMSprop(netG.parameters(), lr=lr)"
   ],
   "id": "fa76666595497e01",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T01:51:08.615365Z",
     "start_time": "2024-08-29T01:00:08.665227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training Loop\n",
    "num_epochs = 1000\n",
    "n_critic = 5  # number of critic iterations per generator iteration\n",
    "lambda_gp = 10  # Gradient penalty lambda hyperparameter\n",
    "\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "\n",
    "# Gradient penalty function\n",
    "def compute_gradient_penalty(critic, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN-GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    alpha = torch.rand(real_samples.size(0), 1, 1, 1, device=device)\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    critic_interpolates = critic(interpolates)\n",
    "    # Create a tensor of ones with the same shape as critic_interpolates\n",
    "    fake = torch.ones(critic_interpolates.size(), device=device, requires_grad=False)\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=critic_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        \n",
    "        ############################\n",
    "        # (1) Update D network\n",
    "        ###########################\n",
    "        for _ in range(n_critic):\n",
    "            netC.zero_grad()\n",
    "            \n",
    "            # Train with real\n",
    "            real_images = data[0].to(device)\n",
    "            b_size = real_images.size(0)\n",
    "            \n",
    "            # Train with fake\n",
    "            noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "            fake = netG(noise)\n",
    "            \n",
    "            # Critic loss\n",
    "            real_validity = netC(real_images).view(-1)\n",
    "            fake_validity = netC(fake.detach()).view(-1)\n",
    "            \n",
    "            # Gradient penalty\n",
    "            gradient_penalty = compute_gradient_penalty(netC, real_images.data, fake.data)\n",
    "            \n",
    "            # Wasserstein loss\n",
    "            d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + lambda_gp * gradient_penalty\n",
    "            \n",
    "            d_loss.backward()\n",
    "            optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        \n",
    "        # Generate fake images\n",
    "        fake = netG(noise)\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        fake_validity = netC(fake).view(-1)\n",
    "        g_loss = -torch.mean(fake_validity)\n",
    "        \n",
    "        g_loss.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     d_loss.item(), g_loss.item()))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(g_loss.item())\n",
    "        D_losses.append(d_loss.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1"
   ],
   "id": "28dc0b5eec001a8a",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T01:51:11.335363Z",
     "start_time": "2024-08-29T01:51:11.262375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "d46ccdec0557ed5d",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T23:27:08.411854Z",
     "start_time": "2024-08-20T23:27:06.720542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ],
   "id": "c09362bc13dbbcd7",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T01:51:16.231862Z",
     "start_time": "2024-08-29T01:51:15.537159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Grab a batch of real images from the dataloader\n",
    "real_batch = next(iter(dataloader))\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "plt.show()"
   ],
   "id": "68cd2ef43ee60789",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T01:51:24.233588Z",
     "start_time": "2024-08-29T01:51:24.228313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Saving the generator\n",
    "def save_generator(generator, path):\n",
    "    torch.save({\n",
    "        'model_state_dict': generator.state_dict(),\n",
    "        'model_architecture': str(generator),  # Save architecture as string\n",
    "        # Add any other information you want to save\n",
    "    }, path)\n",
    "\n",
    "# Loading the generator\n",
    "def load_generator(path, GeneratorClass):\n",
    "    checkpoint = torch.load(path)\n",
    "    generator = GeneratorClass()  # You need to define the generator architecture\n",
    "    generator.load_state_dict(checkpoint['model_state_dict'])\n",
    "    return generator"
   ],
   "id": "7ecb417ad03bc340",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T01:51:29.777026Z",
     "start_time": "2024-08-29T01:51:29.766733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Saving the generator\n",
    "def save_critic(critic, path):\n",
    "    torch.save({\n",
    "        'model_state_dict': critic.state_dict(),\n",
    "        'model_architecture': str(critic),  # Save architecture as string\n",
    "        # Add any other information you want to save\n",
    "    }, path)\n",
    "\n",
    "# Loading the generator\n",
    "def load_critic(path, CriticClass):\n",
    "    checkpoint = torch.load(path)\n",
    "    critic = CriticClass()  # You need to define the generator architecture\n",
    "    critic.load_state_dict(checkpoint['model_state_dict'])\n",
    "    return critic"
   ],
   "id": "fc689620f5a2be31",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T01:51:49.058613Z",
     "start_time": "2024-08-29T01:51:48.724695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_generator(netG, '500_epoch/generator.pth')\n",
    "# loaded_gene\n",
    "# rator = load_generator('generator.pth', GeneratorClass)"
   ],
   "id": "57266b273a348183",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T01:51:50.408295Z",
     "start_time": "2024-08-29T01:51:50.255082Z"
    }
   },
   "cell_type": "code",
   "source": "save_critic(netC, '500_epoch/critic.pth')",
   "id": "169e00f74e442373",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "noise = torch.randn(1, nz, 1, 1, device=device)\n",
    "output = netG(noise)\n",
    "output.shape\n",
    "#plt.imshow(output)"
   ],
   "id": "3d9d95c3fddb9c42",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def visualize_output(output, nrow=8):\n",
    "    # Ensure the output is on CPU and detach from computation graph\n",
    "    output = output.cpu().detach()\n",
    "\n",
    "    # Normalize the output to range [0, 1]\n",
    "    output = (output + 1) / 2.0  # Assuming output is in range [-1, 1]\n",
    "    output = torch.clamp(output, 0, 1)\n",
    "\n",
    "    # Convert to grid of images\n",
    "    grid = vutils.make_grid(output, nrow=nrow, padding=2, normalize=False)\n",
    "\n",
    "    # Convert to numpy and transpose\n",
    "    grid = grid.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    # Display the image\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(grid)\n",
    "    plt.show()"
   ],
   "id": "b2faa0c86bd97338",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualize_output(output)",
   "id": "407eb0726585303",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "711dc475d26ad557",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
